# Videos

Notes about recording videos (for YouTube), in particular my Nix recordings
series.

The `nix-rec/index.md` file is rendered at `https://noteed.com/videos/`.

Videos are uploaded to
https://www.youtube.com/channel/UCnFhDQZWUBKHfIOHxUXlTsA.


# Listing

- [The Nix recording #1 - Creating a virtual machine with doctl](https://www.youtube.com/watch?v=LeasCiM0NRI)


# Precautions

- Make sure the `direnv` hook is loaded. Digital Ocean credentials are present
  in the `digitalocean/.envrc file`, and thus in the environment variables.
  They should not be leaked.
- Use the `list-droplets.sh` script:
  - To make sure a `nix-rec` Droplet doesn't already exist (otherwise the
    scripts may try to connect to the wrong VM).
  - To make sure the VM is deleted and doesn't incure additional costs.
- Make sure the SSH key is loaded in the SSH agent.
- Sometimes, the SSH `known_hosts` file already contains the VM that we are
  creating, which will conflict with the fact we expect to have to accept the
  new host key.


# Checklist

- Make sure `noteed.com/videos` has a dedicated page per video (a link to
  YouTube, and a transcript)
- Make sure the description is filled on YouTube, possibly updated with links
  to the next videos.


# Terminal recording

```
$ cd digitalocean/
$ ../nix-rec/01-create-droplet/render.sh
$ cd ../nix-rec/01-create-droplet/
$ ./assemble.sh
```

The last step, `assemble.sh`, generates an MP4 video from a series of PNGs. In
addition of the PNGs generated by termtosvg, it also adds the frames for the
title sequence, which is generated in `00-title-youtube`. 

The last step uses a `listing.txt` file to control the duration of each image.
This is further manually edited to introduce additional delays, to allow the
necessary room for the voice over.


# Voice recording

```
$ ffmpeg -y -nostdin -hide_banner -f alsa -i default voice.wav
```

Hit `Ctrl-C` to stop the recording.


# Removing background noise

Using SoX, the three steps are as follow.

- Record a `noise.wav` file, as you would do for the voice to capture the
  ambiant sounds
- Build a noise profile
- Apply the profile to the voice file with a value around 0.20-0.30.

```
$ ffmpeg -y -nostdin -hide_banner -f alsa -i default noise.wav
$ sox noise.wav -n noiseprof noise.profile
$ sox voice.wav filtered.wav noisered noise.profile 0.30
```

- The command above are based on
  https://unix.stackexchange.com/questions/140398/.
- ffmpeg has some options I have to try:
  https://superuser.com/questions/733061/.


# Multiple audio files

It should be possible to split a longer file containing pauses (silences). But
I need to find the right values first.

```
$ sox -V3 voice-1.wav splitted.wav silence 1 2.0 0.5% 1 0.3 0.5% : newfile : restart
```

So instead I use the `./record-voice.sh` script, which creates a new file with
a timestamp in the filename, so that I can call it repeatedly. I'd like to use
maybe an XBox controller to record/stop, to avoid hearing my keyboard when I
hit Ctrl-C.

Concatenate multiple files in one:

```
$ sox sentences/filtered-161460*wav voice-over.wav
```

To sync the above voice over files with the video, I generate silences, that I
name in such a way they are listing in the right spot in the `filtered-*.wav`
above. E.g. for 8 seconds of silence:

```
$ sox -n -b 16 -r 48000 -c 2 silence-8-seconds.wav trim 0.0 8.0
```

Alternatively I guess I can import all the voice over files at a time in
Blender and move them around.


# Merge audio and video

```
$ ffmpeg -i video.mp4 -i voice-over.wav \
  -c:v copy -c:a aac -filter:a volume=6dB 
  video-voice-over.mp4
```

The `-filter:a volume=6dB` is optional and makes the audio a bit louder.


# Video editing

To place a yellow highlighting line over some characters in the video, I
generate MP4s that are overlayed in Blender on top of the main video.

- Go to the right frame
- Add a "Movie"
- Add a "Transform" effect strip (which is linked to the Movie)
- The Transform is used to place the Movie in the correct spot, and possibly
  stretch it
- In Adjust, Compositing, select the Darken Blend mode
- I have to select the "bicubic" interpolation instead of the default
  "bilinear" because the later results in a rendering artefact: a black border
  appears around the overlayed video.

See the `highlighter/` directory for the MP4 files.


# YouTube brand account

If you have a Google account, you already have a YouTube account. To use a
different account to publish videos, you have to create a "brand" account.

This is done through the YouTube web interface (this is not available on the
Android app) by creating a new channel, which allows to create a brand account.

Long story short, my brand account is "noteed" (although this can be easily
renamed), and its URL is
https://www.youtube.com/channel/UCnFhDQZWUBKHfIOHxUXlTsA.


# Profile picture

You can set a profile picture on this page
https://studio.youtube.com/channel/UCnFhDQZWUBKHfIOHxUXlTsA/editing/images.

In my case, I have made a simple SVG file that I exported as PNG:

```
$ inkscape -w 512 -h 512 letter-n.svg --export-filename letter-n.png
```

TODO: I tried to use `IBM Plex Mono` but I don't think it worked. Anyway, the
monospace font I use in xterm, and thus that I want to replicate in my
recordings,  is `DejaVu Sans Mono for Powerline`, so I have to change that.


# Title / thumbnail

For each video, it is possible to choose a specific frame to represent the
video in listings, but it is also possible to upload an image. Just like for
the profile picture, I tried to do a simple SVG, which again is exported as
PNG.

```
$ inkscape title.svg --export-filename title.png -b '#ffffff' -y 255
```

The `-b` option specifies a background color, and the `-y` specifies the
background opacity.


# Interactive terminal setup

On my laptop, I'm using two side-by-side xterm windows. As it happens, I have
91 columns (each). (And I have 51 lines.)

The following two commands results in a 91x24 terminal, with a nice border,
suitable for "live" recording, or streaming:

```
$ xterm -b 142 -fa 'DejaVu Sans Mono for Powerline' -fs 14
$ kitty -o include=~/projects/learn-kitty/CLRS.conf \
    -o font_size=14 -o window_padding_width=45.0 -o enable_audio_bell=no
```

The results are similar, although there is a small vertical difference.


# Scripted terminal setup

By modifying termtosvg's source code, I've been able to replicate closely the
above kitty or xterm terminal setups. The modifications are at
https://github.com/noteed/termtosvg.

I'm rendering individual frames at 2560x1440 (just like my laptop screen),
convert them to PNGs using inkscape, then assemble them as an MP4 video using
ffmpeg.

The interaction during termtosvg recording is scripted using a GNU Screen
session and sending it commands, or using expect. The former is useful for
something like Vim, while the later is useful if I have to enter some input
only when some specific output has been read.

I guess it is possible to further alter termtosvg to recognise some output and
let it enter the input itself at the right time.

Note: I had to create a `.screenrc` to get correct colors within screen.


# Weight

In a very simple test, where I run Vim (which shows its title screen), insert
"Hello.", then quit with ":q":

- The MP4 video: 140K
- The 19 frames as SVGs: 144K
- The 19 frames as PNGs: 988K


# Normal terminal

I'm trying to replicate my normal xterm terminal with kitty:

```
$ kitty -o include=~/projects/learn-kitty/CLRS.conf -o font_size=8 -o window_padding_width=0 -o enable_audio_bell=no -o window_border_width=0 -o window_margin_width=0 -o placement_strategy=top-left -o draw_minimal_borders=no
```

Some options are not needed. The `placement_strategy` seems interesting; I
should try it for the presentation case.


# Other approaches

- https://news.ycombinator.com/item?id=21751395, which mentions ttyrec.
- https://intoli.com/blog/terminal-recorders/#conclusion
- https://github.com/jwodder/ttyrec2video
- https://github.com/LegNeato/asciinema-rs. This uses pty-shell, which might be
  handy to instrument a shell.
- https://github.com/marionebl/svg-term-cli
